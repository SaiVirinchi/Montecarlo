{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PINN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gtoYEwCw0S-",
        "cellView": "form"
      },
      "source": [
        "#@title PINN Heat Diffusion\n",
        "!pip install pyDOE\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "from scipy.interpolate import griddata\n",
        "from pyDOE import lhs\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import time\n",
        "import matplotlib.gridspec as gridspec\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "\n",
        "np.random.seed(1234)\n",
        "tf.set_random_seed(1234)\n",
        "\n",
        "\n",
        "class PhysicsInformedNN:\n",
        "    # Initialize the class\n",
        "    def __init__(self, x0, u0, tb, X_f, layers, lb, ub):\n",
        "        \n",
        "        X0 = np.concatenate((x0, 0*x0), 1) # (x0, 0)\n",
        "        X_lb = np.concatenate((0*tb + lb[0], tb), 1) # (lb[0], tb)\n",
        "        X_ub = np.concatenate((0*tb + ub[0], tb), 1) # (ub[0], tb)\n",
        "        \n",
        "        self.lb = lb\n",
        "        self.ub = ub\n",
        "               \n",
        "        self.x0 = X0[:,0:1]\n",
        "        self.t0 = X0[:,1:2]\n",
        "\n",
        "        self.x_lb = X_lb[:,0:1]\n",
        "        self.t_lb = X_lb[:,1:2]\n",
        "\n",
        "        self.x_ub = X_ub[:,0:1]\n",
        "        self.t_ub = X_ub[:,1:2]\n",
        "        \n",
        "        self.x_f = X_f[:,0:1]\n",
        "        self.t_f = X_f[:,1:2]\n",
        "        \n",
        "        self.u0 = u0\n",
        "        \n",
        "        # Initialize NNs\n",
        "        self.layers = layers\n",
        "        self.weights, self.biases = self.initialize_NN(layers)\n",
        "        \n",
        "        # tf Placeholders        \n",
        "        self.x0_tf = tf.placeholder(tf.float32, shape=[None, self.x0.shape[1]])\n",
        "        self.t0_tf = tf.placeholder(tf.float32, shape=[None, self.t0.shape[1]])\n",
        "        \n",
        "        self.u0_tf = tf.placeholder(tf.float32, shape=[None, self.u0.shape[1]])\n",
        "        \n",
        "        self.x_lb_tf = tf.placeholder(tf.float32, shape=[None, self.x_lb.shape[1]])\n",
        "        self.t_lb_tf = tf.placeholder(tf.float32, shape=[None, self.t_lb.shape[1]])\n",
        "        \n",
        "        self.x_ub_tf = tf.placeholder(tf.float32, shape=[None, self.x_ub.shape[1]])\n",
        "        self.t_ub_tf = tf.placeholder(tf.float32, shape=[None, self.t_ub.shape[1]])\n",
        "        \n",
        "        self.x_f_tf = tf.placeholder(tf.float32, shape=[None, self.x_f.shape[1]])\n",
        "        self.t_f_tf = tf.placeholder(tf.float32, shape=[None, self.t_f.shape[1]])\n",
        "\n",
        "        # tf Graphs\n",
        "        self.u0_pred, _ = self.net_uv(self.x0_tf, self.t0_tf)\n",
        "        self.u_lb_pred, self.u_x_lb_pred = self.net_uv(self.x_lb_tf, self.t_lb_tf)\n",
        "        self.u_ub_pred, self.u_x_ub_pred = self.net_uv(self.x_ub_tf, self.t_ub_tf)\n",
        "        self.f_u_pred = self.net_f_uv(self.x_f_tf, self.t_f_tf)\n",
        "        \n",
        "        # Loss\n",
        "        self.loss = tf.reduce_mean(tf.square(self.u0_tf - self.u0_pred)) + \\\n",
        "                    tf.reduce_mean(tf.square(self.u_ub_pred)) + \\\n",
        "                    tf.reduce_mean(tf.square(self.u_lb_pred)) + \\\n",
        "                    tf.reduce_mean(tf.square(self.u_ub_pred -  self.u_lb_pred)) + \\\n",
        "                    tf.reduce_mean(tf.square(self.f_u_pred)) \n",
        "                    \n",
        "        \n",
        "        # Optimizers\n",
        "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \n",
        "                                                                method = 'L-BFGS-B', \n",
        "                                                                options = {'maxiter': 50000,\n",
        "                                                                           'maxfun': 50000,\n",
        "                                                                           'maxcor': 50,\n",
        "                                                                           'maxls': 50,\n",
        "                                                                           'ftol' : 1.0* np.finfo(float).eps})\n",
        "    \n",
        "        self.optimizer_Adam = tf.train.AdamOptimizer()\n",
        "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)\n",
        "                \n",
        "        # tf session\n",
        "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
        "                                                     log_device_placement=True))\n",
        "        \n",
        "        init = tf.global_variables_initializer()\n",
        "        self.sess.run(init)\n",
        "              \n",
        "    def initialize_NN(self, layers):        \n",
        "        weights = []\n",
        "        biases = []\n",
        "        num_layers = len(layers) \n",
        "        for l in range(0,num_layers-1):\n",
        "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
        "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
        "            weights.append(W)\n",
        "            biases.append(b)        \n",
        "        return weights, biases\n",
        "        \n",
        "    def xavier_init(self, size):\n",
        "        in_dim = size[0]\n",
        "        out_dim = size[1]        \n",
        "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
        "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
        "    \n",
        "    def neural_net(self, X, weights, biases):\n",
        "        num_layers = len(weights) + 1\n",
        "        \n",
        "        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n",
        "        for l in range(0,num_layers-2):\n",
        "            W = weights[l]\n",
        "            b = biases[l]\n",
        "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
        "        W = weights[-1]\n",
        "        b = biases[-1]\n",
        "        Y = tf.add(tf.matmul(H, W), b)\n",
        "        return Y\n",
        "    \n",
        "    def net_uv(self, x, t):\n",
        "        X = tf.concat([x,t],1)\n",
        "        \n",
        "        uv = self.neural_net(X, self.weights, self.biases)\n",
        "        u = uv\n",
        "        print(\"doubt\",np.shape(uv),np.shape(u))\n",
        "        \n",
        "        u_x = tf.gradients(u, x)[0]\n",
        "\n",
        "        return u, u_x\n",
        "\n",
        "    def net_f_uv(self, x, t):\n",
        "        u, u_x = self.net_uv(x,t)\n",
        "        global nu \n",
        "        u_t = tf.gradients(u, t)[0]\n",
        "        u_xx = tf.gradients(u_x, x)[0]\n",
        "        \n",
        "        f_u = u_t - 200*u_xx  \n",
        "        \n",
        "        return f_u\n",
        "    \n",
        "    def callback(self, loss):\n",
        "        print('Loss:', loss)\n",
        "        \n",
        "    def train(self, nIter):\n",
        "        \n",
        "        tf_dict = {self.x0_tf: self.x0, self.t0_tf: self.t0,\n",
        "                   self.u0_tf: self.u0,\n",
        "                   self.x_lb_tf: self.x_lb, self.t_lb_tf: self.t_lb,\n",
        "                   self.x_ub_tf: self.x_ub, self.t_ub_tf: self.t_ub,\n",
        "                   self.x_f_tf: self.x_f, self.t_f_tf: self.t_f}\n",
        "        \n",
        "        start_time = time.time()\n",
        "        for it in range(nIter):\n",
        "            self.sess.run(self.train_op_Adam, tf_dict)\n",
        "            \n",
        "            # Print\n",
        "            if it % 10 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                loss_value = self.sess.run(self.loss, tf_dict)\n",
        "                print('It: %d, Loss: %.3e, Time: %.2f' % \n",
        "                      (it, loss_value, elapsed))\n",
        "                start_time = time.time()\n",
        "                                                                                                                          \n",
        "        self.optimizer.minimize(self.sess, \n",
        "                                feed_dict = tf_dict,         \n",
        "                                fetches = [self.loss], \n",
        "                                loss_callback = self.callback)        \n",
        "                                    \n",
        "    \n",
        "    def predict(self, X_star):\n",
        "        \n",
        "        tf_dict = {self.x0_tf: X_star[:,0:1], self.t0_tf: X_star[:,1:2]}\n",
        "        \n",
        "        u_star = self.sess.run(self.u0_pred, tf_dict)   \n",
        "        \n",
        "        \n",
        "        tf_dict = {self.x_f_tf: X_star[:,0:1], self.t_f_tf: X_star[:,1:2]}\n",
        "        \n",
        "        f_u_star = self.sess.run(self.f_u_pred, tf_dict)\n",
        "               \n",
        "        return u_star,f_u_star\n",
        "            \n",
        "if __name__ == \"__main__\": \n",
        "         \n",
        "    \n",
        "    lb = np.array([0, 0]) # x , t\n",
        "\n",
        "    ub = np.array([100, 4000])\n",
        "\n",
        "    N0 = 10\n",
        "    N_b = 100\n",
        "    N_f = 50000\n",
        "    layers = [2, 100, 100, 100, 100, 1]\n",
        "    nu = 100\n",
        "        \n",
        "    from scipy import special\n",
        "    \n",
        "    \n",
        "    def diffusion(xmax, tmax, nu):\n",
        "        plate_length = xmax\n",
        "        nx = plate_length\n",
        "        max_iter_time = tmax\n",
        "        nt = max_iter_time\n",
        "\n",
        "        alpha = nu\n",
        "        delta_x = 1\n",
        "        dx = delta_x\n",
        "        x = np.zeros(nx)\n",
        "        t = np.zeros(nt)\n",
        "        delta_t = (delta_x ** 2)/(4 * alpha)\n",
        "        dt = delta_t\n",
        "        gamma = (alpha * delta_t) / (delta_x ** 2)\n",
        "\n",
        "\n",
        "        # X Loop\n",
        "        for i in range(0,nx):\n",
        "            x[i] = i*dx\n",
        "        # T Loop\n",
        "        for i in range(0,nt):\n",
        "            t[i] = i*dt\n",
        "\n",
        "\n",
        "\n",
        "        # Initialize solution: the grid of u(k, i, j)\n",
        "        u = np.empty((plate_length,max_iter_time))\n",
        "\n",
        "        # Initial condition everywhere inside the grid\n",
        "\n",
        "        u_initial = 100*np.sin(x*np.pi/(xmax)) #.random.uniform(low=50, high=50, size=(nx))\n",
        "        \n",
        "\n",
        "        # Boundary conditions\n",
        "        u_top = 0.0\n",
        "        u_bottom = 0.0\n",
        "\n",
        "        # Set the initial condition\n",
        "        u[:,0] = u_initial\n",
        "\n",
        "        # Set the boundary conditions\n",
        "        u[(nx-1):,:] = u_top\n",
        "        u[:1,:] = u_bottom\n",
        "\n",
        "        if dt <= (dx**2)/(2*alpha):\n",
        "            print(\"you are lucky\")\n",
        "        else: \n",
        "            print(\"hmmm\",dt,(dx**2)/(4*alpha))\n",
        "\n",
        "        print(\"dw\",dt,dx)\n",
        "\n",
        "        def calculate(u):\n",
        "            for k in range(0, nt-1):\n",
        "                for i in range(1, nx-1):\n",
        "                    #print(i,k)\n",
        "                    u[i,k + 1] = gamma * (u[i+1][k] + u[i-1][k] - 2*u[i][k]) + u[i][k]\n",
        "            \n",
        "            print(\"dadd\",np.shape(u),np.shape(t))\n",
        "            return u,x,t\n",
        "\n",
        "\n",
        "\n",
        "        # Do the calculation here\n",
        "        u,x,t = calculate(u)\n",
        "        return u,x,t\n",
        "  \n",
        "    Exact, xa, ta = diffusion( 100, 4000, nu)\n",
        "    x = xa[:,None]\n",
        "    t = ta[:,None]\n",
        "    Exact_u = Exact\n",
        "    print(np.shape(Exact),np.shape(x),np.shape(t))\n",
        "    X, T = np.meshgrid(x,t)\n",
        "    \n",
        "    X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
        "    u_star = Exact_u.T.flatten()[:,None]\n",
        "    \n",
        "    ###########################\n",
        "    \n",
        "    idx_x = np.random.choice(x.shape[0], N0, replace=False)\n",
        "\n",
        "    x0 = x[idx_x,:]\n",
        "    u0 = Exact_u[idx_x,0:1]\n",
        "    \n",
        "\n",
        "    idx_t = np.random.choice(t.shape[0], N_b, replace=False)\n",
        "    tb = t[idx_t,:]\n",
        "    #print(\"idx\",idx_x,idx_t,tb)\n",
        "    \n",
        "    X_f = lb + (ub-lb)*lhs(2, N_f)\n",
        "\n",
        "    model = PhysicsInformedNN(x0, u0, tb, X_f, layers, lb, ub)\n",
        "\n",
        "             \n",
        "    start_time = time.time()                \n",
        "    model.train(5000)\n",
        "    elapsed = time.time() - start_time                \n",
        "    print('Training time: %.4f' % (elapsed))\n",
        "    \n",
        "        \n",
        "    u_pred, f_u_pred = model.predict(X_star)\n",
        "  \n",
        "            \n",
        "    error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
        "    print('Error u: %e' % (error_u))\n",
        "\n",
        "    \n",
        "    U_pred = griddata(X_star, u_pred.flatten(), (X, T), method='cubic')\n",
        "\n",
        "    FU_pred = griddata(X_star, f_u_pred.flatten(), (X, T), method='cubic')   \n",
        "    \n",
        "    \n",
        "    ######################################################################\n",
        "    ############################# Plotting ###############################\n",
        "    ######################################################################    \n",
        "    \n",
        "      \n",
        "    i = 0 # value of t\n",
        "\n",
        "    plt.plot(x,Exact_u[:,i], linewidth = 2,label = 'Exact')       \n",
        "    plt.plot(x,U_pred[i,:], 'r', linewidth = 2, label = 'Prediction')\n",
        "    plt.xlabel('x')\n",
        "    plt.ylabel('T(t,x)')\n",
        "    plt.legend(loc='upper center')\n",
        "    plt.show()    \n",
        "\n",
        "    import os\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    import imageio\n",
        "    filenames = []\n",
        "    for i in range(0,4000,50):\n",
        "        plt.plot(x,Exact_u[:,i], linewidth = 2,label = 'Exact')       \n",
        "        plt.plot(x,U_pred[i,:], 'r', linewidth = 2, label = 'Prediction')\n",
        "        plt.scatter(x0,u0,label = 'Initial')\n",
        "        plt.xlabel('x')\n",
        "        plt.ylabel('T(t,x)')\n",
        "        plt.title('Time %i' % (i))\n",
        "        plt.legend(loc='upper right')\n",
        "        \n",
        "        # create file name and append it to a list\n",
        "        filename = f'{i}.png'\n",
        "        filenames.append(filename)\n",
        "        \n",
        "        # save frame\n",
        "        plt.savefig(filename)\n",
        "        plt.close()\n",
        "    # build gif\n",
        "    with imageio.get_writer('mygif.gif', mode='I') as writer:\n",
        "        for filename in filenames:\n",
        "            image = imageio.imread(filename)\n",
        "            writer.append_data(image)\n",
        "    \n",
        "            \n",
        "    # Remove files\n",
        "    for filename in set(filenames):\n",
        "        os.remove(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "4pmUZCJ-vnUu"
      },
      "source": [
        "#@title PINN Neutron Diffusion 1D Final\n",
        "\n",
        "\n",
        "!pip install pyDOE\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "import os\n",
        "\n",
        "def restore(session, save_file, raise_if_not_found=False, copy_mismatched_shapes=False):\n",
        "    if not os.path.exists(save_file) and raise_if_not_found:\n",
        "        raise Exception('File %s not found' % save_file)\n",
        "    reader = tf.train.NewCheckpointReader(save_file)\n",
        "    saved_shapes = reader.get_variable_to_shape_map()\n",
        "    var_names = sorted([(var.name, var.name.split(':')[0]) for var in tf.global_variables()\n",
        "            if var.name.split(':')[0] in saved_shapes])\n",
        "    var_name_to_var = {var.name : var for var in tf.global_variables()}\n",
        "    restore_vars = []\n",
        "    restored_var_names = set()\n",
        "    restored_var_new_shape = []\n",
        "    print('Restoring:')\n",
        "    with tf.variable_scope(tf.get_variable_scope(), reuse=True):\n",
        "        for var_name, saved_var_name in var_names:\n",
        "            if 'global_step' in var_name:\n",
        "                restored_var_names.add(saved_var_name)\n",
        "                continue\n",
        "            curr_var = var_name_to_var[var_name]\n",
        "            var_shape = curr_var.get_shape().as_list()\n",
        "            if var_shape == saved_shapes[saved_var_name]:\n",
        "                restore_vars.append(curr_var)\n",
        "                print(str(saved_var_name) + ' -> \\t' + str(var_shape) + ' = ' +\n",
        "                      str(int(np.prod(var_shape) * 4 / 10**6)) + 'MB')\n",
        "                restored_var_names.add(saved_var_name)\n",
        "            else:\n",
        "                print('Shape mismatch for var', saved_var_name, 'expected', var_shape,\n",
        "                      'got', saved_shapes[saved_var_name])\n",
        "                restored_var_new_shape.append((saved_var_name, curr_var, reader.get_tensor(saved_var_name)))\n",
        "                print('bad things')\n",
        "    ignored_var_names = sorted(list(set(saved_shapes.keys()) - restored_var_names))\n",
        "    print('\\n')\n",
        "    if len(ignored_var_names) == 0:\n",
        "        print('Restored all variables')\n",
        "    else:\n",
        "        print('Did not restore:' + '\\n\\t'.join(ignored_var_names))\n",
        "\n",
        "    if len(restore_vars) > 0:\n",
        "        saver = tf.train.Saver(restore_vars)\n",
        "        saver.restore(session, save_file)\n",
        "\n",
        "    if len(restored_var_new_shape) > 0 and copy_mismatched_shapes:\n",
        "        print('trying to restore misshapen variables')\n",
        "        assign_ops = []\n",
        "        for name, kk, vv in restored_var_new_shape:\n",
        "            copy_sizes = np.minimum(kk.get_shape().as_list(), vv.shape)\n",
        "            slices = [slice(0,cs) for cs in copy_sizes]\n",
        "            print('copy shape', name, kk.get_shape().as_list(), '->', copy_sizes.tolist())\n",
        "            new_arr = session.run(kk)\n",
        "            new_arr[slices] = vv[slices]\n",
        "            assign_ops.append(tf.assign(kk, new_arr))\n",
        "        session.run(assign_ops)\n",
        "        print('Copying unmatched weights done')\n",
        "    print('Restored %s' % save_file)\n",
        "    try:\n",
        "        start_iter = int(save_file.split('-')[-1])\n",
        "    except ValueError:\n",
        "        print('Could not parse start iter, assuming 0')\n",
        "        start_iter = 0\n",
        "    return start_iter\n",
        "\n",
        "\n",
        "def restore_from_dir(sess, folder_path, raise_if_not_found=False, copy_mismatched_shapes=False):\n",
        "    start_iter = 0\n",
        "    ckpt = tf.train.get_checkpoint_state(folder_path)\n",
        "    if ckpt and ckpt.model_checkpoint_path:\n",
        "        print('Restoring')\n",
        "        start_iter = restore(sess, ckpt.model_checkpoint_path, raise_if_not_found, copy_mismatched_shapes)\n",
        "    else:\n",
        "        if raise_if_not_found:\n",
        "            raise Exception('No checkpoint to restore in %s' % folder_path)\n",
        "        else:\n",
        "            print('No checkpoint to restore in %s' % folder_path)\n",
        "    return start_iter\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "from scipy.interpolate import griddata\n",
        "from pyDOE import lhs\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import time\n",
        "import matplotlib.gridspec as gridspec\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "\n",
        "np.random.seed(1234)\n",
        "tf.set_random_seed(1234)\n",
        "\n",
        "class PhysicsInformedNN:\n",
        "    # Initialize the class\n",
        "    def __init__(self, x0, u0, v0, x1, u1, v1, X_f, layers, lb, ub):\n",
        "        \n",
        "        X0 = x0 # (x0, 0)\n",
        "        X1 = x1\n",
        "\n",
        "        self.lb = lb\n",
        "        self.ub = ub\n",
        "\n",
        "        \n",
        "               \n",
        "        self.x0 = X0\n",
        "        self.x1 = X1\n",
        "\n",
        "        \n",
        "        self.x_f = X_f\n",
        "        \n",
        "        self.u0 = u0\n",
        "        self.v0 = v0\n",
        "\n",
        "        self.u1 = u1\n",
        "        self.v1 = v1\n",
        "        \n",
        "        # Initialize NNs\n",
        "        self.layers = layers\n",
        "        self.weights, self.biases = self.initialize_NN(layers)\n",
        "        \n",
        "        # tf Placeholders        \n",
        "\n",
        "        self.x0_tf = tf.placeholder(tf.float32, shape=[None, self.x0.shape[1]])\n",
        "        self.x1_tf = tf.placeholder(tf.float32, shape=[None, self.x1.shape[1]])\n",
        "\n",
        "        self.u0_tf = tf.placeholder(tf.float32, shape=[None, self.u0.shape[1]])\n",
        "        self.v0_tf = tf.placeholder(tf.float32, shape=[None, self.v0.shape[1]])\n",
        "        \n",
        "        self.u1_tf = tf.placeholder(tf.float32, shape=[None, self.u1.shape[1]])\n",
        "        self.v1_tf = tf.placeholder(tf.float32, shape=[None, self.v1.shape[1]])\n",
        "        \n",
        "        self.x_f_tf = tf.placeholder(tf.float32, shape=[None, self.x_f.shape[1]])\n",
        "\n",
        "\n",
        "        #tf save\n",
        "        self.saver = tf.train.Saver()\n",
        "\n",
        "        # tf Graphs\n",
        "        self.u0_pred, self.v0_pred, _ , _ = self.net_uv(self.x0_tf)\n",
        "        self.u1_pred, self.v1_pred, _ , _ = self.net_uv(self.x1_tf)\n",
        "        self.f_u_pred, self.f_v_pred = self.net_f_uv(self.x_f_tf)\n",
        "        \n",
        "        # Loss\n",
        "        self.loss = tf.reduce_mean(tf.square(self.u0_tf - self.u0_pred)) + \\\n",
        "                    tf.reduce_mean(tf.square(self.v0_tf - self.v0_pred)) + \\\n",
        "                    tf.reduce_mean(tf.square(self.u1_tf - self.u1_pred)) + \\\n",
        "                    tf.reduce_mean(tf.square(self.f_v_pred)) + \\\n",
        "                    tf.reduce_mean(tf.square(self.f_u_pred))\n",
        "        \n",
        "        # Optimizers\n",
        "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \n",
        "                                                                method = 'L-BFGS-B', \n",
        "                                                                options = {'maxiter': 50000,\n",
        "                                                                           'maxfun': 50000,\n",
        "                                                                           'maxcor': 50,\n",
        "                                                                           'maxls': 50,\n",
        "                                                                           'ftol' : 1.0* np.finfo(float).eps})\n",
        "    \n",
        "        self.optimizer_Adam = tf.train.AdamOptimizer()\n",
        "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)\n",
        "                \n",
        "\n",
        "        \n",
        "\n",
        "        # tf session\n",
        "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
        "                                                     log_device_placement=True))\n",
        "        \n",
        "        init = tf.global_variables_initializer()\n",
        "        self.sess.run(init)\n",
        "\n",
        "        \n",
        "              \n",
        "    def initialize_NN(self, layers):        \n",
        "        weights = []\n",
        "        biases = []\n",
        "        num_layers = len(layers) \n",
        "        for l in range(0,num_layers-1):\n",
        "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
        "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
        "            weights.append(W)\n",
        "            biases.append(b)        \n",
        "        return weights, biases\n",
        "        \n",
        "    def xavier_init(self, size):\n",
        "        in_dim = size[0]\n",
        "        out_dim = size[1]        \n",
        "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
        "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
        "    \n",
        "    def neural_net(self, X, weights, biases):\n",
        "        num_layers = len(weights) + 1\n",
        "        \n",
        "        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n",
        "        for l in range(0,num_layers-2):\n",
        "            W = weights[l]\n",
        "            b = biases[l]\n",
        "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
        "        W = weights[-1]\n",
        "        b = biases[-1]\n",
        "        Y = tf.add(tf.matmul(H, W), b)\n",
        "        return Y\n",
        "    \n",
        "    def net_uv(self, x):\n",
        "        X = x\n",
        "        \n",
        "        uv = self.neural_net(X, self.weights, self.biases)\n",
        "        u = uv[:,0:1]\n",
        "        v = uv[:,1:2]\n",
        "          \n",
        "        u_x = tf.gradients(u, x)[0]\n",
        "        v_x = tf.gradients(v, x)[0]\n",
        "\n",
        "        return u, v, u_x, v_x\n",
        "\n",
        "    def net_f_uv(self, x):\n",
        "        u, v, u_x, v_x = self.net_uv(x)\n",
        "        \n",
        "        u_xx = tf.gradients(u_x, x)[0]\n",
        "        \n",
        "        v_xx = tf.gradients(v_x, x)[0]\n",
        "        \n",
        "        \n",
        "\n",
        "        f_v = d1*u_xx + (-1)*r1*u + (1/k)*(nu*f1*u + nu*f2*v)\n",
        "        f_u = d2*v_xx + (-1)*r2*v + s1*u   \n",
        "        \n",
        "        return f_u, f_v\n",
        "    \n",
        "    def callback(self, loss):\n",
        "        print('Loss:', loss)\n",
        "        \n",
        "    def train(self, nIter):\n",
        "        \n",
        "        tf_dict = {self.x0_tf: self.x0,\n",
        "                   self.x1_tf: self.x1,\n",
        "                   self.u0_tf: self.u0, self.v0_tf: self.v0,\n",
        "                   self.u1_tf: self.u1, self.v1_tf: self.v1,\n",
        "                   self.x_f_tf: self.x_f}\n",
        "        \n",
        "        start_time = time.time()\n",
        "\n",
        "        restore_from_dir(self.sess, \"./ckpt1/\") \n",
        "\n",
        "        for it in range(nIter):\n",
        "            self.sess.run(self.train_op_Adam, tf_dict)\n",
        "            \n",
        "            # Print\n",
        "            if it % 10 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                loss_value = self.sess.run(self.loss, tf_dict)\n",
        "                print('It: %d, Loss: %.3e, Time: %.2f' % \n",
        "                      (it, loss_value, elapsed))\n",
        "                start_time = time.time()\n",
        "            if it % 100 == 0:\n",
        "                self.saver.save(self.sess, './ckpt1/model',global_step=it,meta_graph_suffix='meta', write_meta_graph=True, write_state=True,\n",
        "                                strip_default_attrs=False, save_debug_info=False)\n",
        "\n",
        "        self.optimizer.minimize(self.sess, \n",
        "                                feed_dict = tf_dict,         \n",
        "                                fetches = [self.loss], \n",
        "                                loss_callback = self.callback)        \n",
        "                                    \n",
        "    \n",
        "    def predict(self, X_star):\n",
        "        \n",
        "        tf_dict = {self.x0_tf: X_star[:,0:1]}\n",
        "        \n",
        "        u_star = self.sess.run(self.u0_pred, tf_dict)  \n",
        "        v_star = self.sess.run(self.v0_pred, tf_dict)  \n",
        "        \n",
        "        \n",
        "        tf_dict = {self.x_f_tf: X_star[:,0:1]}\n",
        "        \n",
        "        f_u_star = self.sess.run(self.f_u_pred, tf_dict)\n",
        "        f_v_star = self.sess.run(self.f_v_pred, tf_dict)\n",
        "               \n",
        "        return u_star, v_star, f_u_star, f_v_star\n",
        "    \n",
        "if __name__ == \"__main__\":        \n",
        "    \n",
        "    # Doman bounds\n",
        "    a = 2*np.pi #@param {}\n",
        "    lb = (-1)*a/2\n",
        "    ub = a/2\n",
        "\n",
        "    N0 = 2\n",
        "    N1 = 1\n",
        "    N_f = 40000\n",
        "    layers = [1, 100, 100, 100, 2]\n",
        "        \n",
        "    #CONSTANTS \n",
        "    d1 = 1 #@param {}\n",
        "    d2 = 0.8 #@param {}\n",
        "    r1 = 0.15 #@param {}\n",
        "    r2 = 0.3 #@param {}\n",
        "    s1 = 0.3 #@param {}\n",
        "    f1 = 0.55 #@param {}\n",
        "    f2 = 0.7 #@param {}\n",
        "    F = 2.5 #@param {}\n",
        "    nu = 1\n",
        "    k = ( (r2 + d2*((np.pi/a)**2)) * nu*f1 + s1*nu*f2) / ( (d1*((np.pi/a)**2) + r1) * (d2 * ((np.pi/a)**2) + r2))\n",
        "\n",
        "    x = np.linspace(lb,ub,2001)\n",
        "    x = np.reshape(x,(2001,1))\n",
        "\n",
        "    Exact_u = F * np.cos((np.pi*x)/a)\n",
        "    Exact_v = (F * np.cos((np.pi*x)/a))*s1/(r2+d2*((np.pi/a)**2))\n",
        "    \n",
        "\n",
        "    X_star = x.flatten()[:,None]\n",
        "    u_star = Exact_u.T.flatten()[:,None]\n",
        "    v_star = Exact_v.T.flatten()[:,None]\n",
        "    ###########################\n",
        "    \n",
        "    idx_x = np.array((0,2000))\n",
        "    x0 = x[idx_x,:]\n",
        "    u0 = Exact_u[idx_x,:]\n",
        "    v0 = Exact_v[idx_x,:]\n",
        "\n",
        "    idx_x = np.random.choice(x.shape[0], N1, replace=False)\n",
        "    x1 = x[idx_x,:]\n",
        "    print(x1,\"yo\")\n",
        "    u1 = Exact_u[idx_x,:]\n",
        "    v1 = Exact_v[idx_x,:]\n",
        "    \n",
        "    \n",
        "    X_f = lb + (ub-lb)*lhs(1, N_f)\n",
        "\n",
        "    print(X_f.shape)        \n",
        "    model = PhysicsInformedNN(x0, u0, v0, x1, u1, v1, X_f, layers, lb, ub)\n",
        "    \n",
        "    #@markdown Choose number of epoch\n",
        "    epoch = 1000 #@param {type:\"slider\", min:1000, max:10000, step:10}\n",
        "             \n",
        "    start_time = time.time()                \n",
        "    model.train(epoch)\n",
        "    elapsed = time.time() - start_time                \n",
        "    print('Training time: %.4f' % (elapsed))\n",
        "    \n",
        "        \n",
        "    u_pred, v_pred, f_u_pred, f_v_pred = model.predict(X_star)\n",
        "    h_pred = np.sqrt(u_pred**2 + v_pred**2)\n",
        "            \n",
        "    error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
        "    error_v = np.linalg.norm(v_star-v_pred,2)/np.linalg.norm(v_star,2)\n",
        "    print('Error u: %e' % (error_u))\n",
        "    print('Error v: %e' % (error_v))\n",
        "\n",
        "    \n",
        " \n",
        "    ######################################################################\n",
        "    ############################# Plotting ###############################\n",
        "    ######################################################################    \n",
        "    \n",
        "      \n",
        "\n",
        "    plt.plot(x,Exact_u[:], linewidth = 2,label = 'Exact')  \n",
        "    plt.scatter(x0,u0) \n",
        "    plt.scatter(x1,u1)     \n",
        "    plt.plot(x,u_pred[:], 'r', linewidth = 2, label = 'Prediction')\n",
        "    plt.xlabel('x')\n",
        "    plt.ylabel('phi1(t,x)')  \n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "    \n",
        "    plt.plot(x,Exact_v[:], linewidth = 2,label = 'Exact')       \n",
        "    plt.plot(x,v_pred[:], 'r', linewidth = 2, label = 'Prediction')\n",
        "    plt.scatter(x0,v0) \n",
        "    plt.xlabel('x')\n",
        "    plt.ylabel('phi2(t,x)')\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()    \n",
        "    \n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TRktTSU30Pea",
        "cellView": "form",
        "outputId": "395397c3-051c-4004-bbc4-82ca349e43fe"
      },
      "source": [
        "#@title PINN Neutron Diffusion in 2D *in progress\n",
        "\n",
        "\n",
        "!pip install pyDOE\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "import os\n",
        "\n",
        "def restore(session, save_file, raise_if_not_found=False, copy_mismatched_shapes=False):\n",
        "    if not os.path.exists(save_file) and raise_if_not_found:\n",
        "        raise Exception('File %s not found' % save_file)\n",
        "    reader = tf.train.NewCheckpointReader(save_file)\n",
        "    saved_shapes = reader.get_variable_to_shape_map()\n",
        "    var_names = sorted([(var.name, var.name.split(':')[0]) for var in tf.global_variables()\n",
        "            if var.name.split(':')[0] in saved_shapes])\n",
        "    var_name_to_var = {var.name : var for var in tf.global_variables()}\n",
        "    restore_vars = []\n",
        "    restored_var_names = set()\n",
        "    restored_var_new_shape = []\n",
        "    print('Restoring:')\n",
        "    with tf.variable_scope(tf.get_variable_scope(), reuse=True):\n",
        "        for var_name, saved_var_name in var_names:\n",
        "            if 'global_step' in var_name:\n",
        "                restored_var_names.add(saved_var_name)\n",
        "                continue\n",
        "            curr_var = var_name_to_var[var_name]\n",
        "            var_shape = curr_var.get_shape().as_list()\n",
        "            if var_shape == saved_shapes[saved_var_name]:\n",
        "                restore_vars.append(curr_var)\n",
        "                print(str(saved_var_name) + ' -> \\t' + str(var_shape) + ' = ' +\n",
        "                      str(int(np.prod(var_shape) * 4 / 10**6)) + 'MB')\n",
        "                restored_var_names.add(saved_var_name)\n",
        "            else:\n",
        "                print('Shape mismatch for var', saved_var_name, 'expected', var_shape,\n",
        "                      'got', saved_shapes[saved_var_name])\n",
        "                restored_var_new_shape.append((saved_var_name, curr_var, reader.get_tensor(saved_var_name)))\n",
        "                print('bad things')\n",
        "    ignored_var_names = sorted(list(set(saved_shapes.keys()) - restored_var_names))\n",
        "    print('\\n')\n",
        "    if len(ignored_var_names) == 0:\n",
        "        print('Restored all variables')\n",
        "    else:\n",
        "        print('Did not restore:' + '\\n\\t'.join(ignored_var_names))\n",
        "\n",
        "    if len(restore_vars) > 0:\n",
        "        saver = tf.train.Saver(restore_vars)\n",
        "        saver.restore(session, save_file)\n",
        "\n",
        "    if len(restored_var_new_shape) > 0 and copy_mismatched_shapes:\n",
        "        print('trying to restore misshapen variables')\n",
        "        assign_ops = []\n",
        "        for name, kk, vv in restored_var_new_shape:\n",
        "            copy_sizes = np.minimum(kk.get_shape().as_list(), vv.shape)\n",
        "            slices = [slice(0,cs) for cs in copy_sizes]\n",
        "            print('copy shape', name, kk.get_shape().as_list(), '->', copy_sizes.tolist())\n",
        "            new_arr = session.run(kk)\n",
        "            new_arr[slices] = vv[slices]\n",
        "            assign_ops.append(tf.assign(kk, new_arr))\n",
        "        session.run(assign_ops)\n",
        "        print('Copying unmatched weights done')\n",
        "    print('Restored %s' % save_file)\n",
        "    try:\n",
        "        start_iter = int(save_file.split('-')[-1])\n",
        "    except ValueError:\n",
        "        print('Could not parse start iter, assuming 0')\n",
        "        start_iter = 0\n",
        "    return start_iter\n",
        "\n",
        "\n",
        "def restore_from_dir(sess, folder_path, raise_if_not_found=False, copy_mismatched_shapes=False):\n",
        "    start_iter = 0\n",
        "    ckpt = tf.train.get_checkpoint_state(folder_path)\n",
        "    if ckpt and ckpt.model_checkpoint_path:\n",
        "        print('Restoring')\n",
        "        start_iter = restore(sess, ckpt.model_checkpoint_path, raise_if_not_found, copy_mismatched_shapes)\n",
        "    else:\n",
        "        if raise_if_not_found:\n",
        "            raise Exception('No checkpoint to restore in %s' % folder_path)\n",
        "        else:\n",
        "            print('No checkpoint to restore in %s' % folder_path)\n",
        "    return start_iter\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "from scipy.interpolate import griddata\n",
        "from pyDOE import lhs\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import time\n",
        "import matplotlib.gridspec as gridspec\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "\n",
        "np.random.seed(1234)\n",
        "tf.set_random_seed(1234)\n",
        "\n",
        "class PhysicsInformedNN:\n",
        "    # Initialize the class\n",
        "    def __init__(self, x0, y0, u0, v0, x1, y1, u1, v1, X_f, layers, lb, ub):\n",
        "        \n",
        "        X0 = x0 # (x0, 0)\n",
        "        X1 = x1\n",
        "\n",
        "\n",
        "        Y0 = y0 # (x0, 0)\n",
        "        Y1 = y1\n",
        "\n",
        "        self.lb = lb\n",
        "        self.ub = ub\n",
        "\n",
        "        \n",
        "               \n",
        "        self.x0 = X0\n",
        "        self.x1 = X1\n",
        "\n",
        "        self.y0 = Y0\n",
        "        self.y1 = Y1\n",
        "\n",
        "        \n",
        "        self.x_f = X_f\n",
        "        self.y_f = Y_f\n",
        "        \n",
        "        self.u0 = u0\n",
        "        self.v0 = v0\n",
        "\n",
        "        self.u1 = u1\n",
        "        self.v1 = v1\n",
        "        \n",
        "        # Initialize NNs\n",
        "        self.layers = layers\n",
        "        self.weights, self.biases = self.initialize_NN(layers)\n",
        "        \n",
        "        # tf Placeholders        \n",
        "\n",
        "        self.x0_tf = tf.placeholder(tf.float32, shape=[None, self.x0.shape[1]])\n",
        "        self.x1_tf = tf.placeholder(tf.float32, shape=[None, self.x1.shape[1]])\n",
        "\n",
        "        self.y0_tf = tf.placeholder(tf.float32, shape=[None, self.y0.shape[1]])\n",
        "        self.y1_tf = tf.placeholder(tf.float32, shape=[None, self.y1.shape[1]])\n",
        "\n",
        "        self.u0_tf = tf.placeholder(tf.float32, shape=[None, self.u0.shape[1]])\n",
        "        self.v0_tf = tf.placeholder(tf.float32, shape=[None, self.v0.shape[1]])\n",
        "        \n",
        "        self.u1_tf = tf.placeholder(tf.float32, shape=[None, self.u1.shape[1]])\n",
        "        self.v1_tf = tf.placeholder(tf.float32, shape=[None, self.v1.shape[1]])\n",
        "        \n",
        "        self.x_f_tf = tf.placeholder(tf.float32, shape=[None, self.x_f.shape[1]])\n",
        "        self.y_f_tf = tf.placeholder(tf.float32, shape=[None, self.y_f.shape[1]])\n",
        "\n",
        "\n",
        "        #tf save\n",
        "        self.saver = tf.train.Saver()\n",
        "\n",
        "        # tf Graphs\n",
        "        self.u0_pred, self.v0_pred, _ , _, _ , _  = self.net_uv(self.x0_tf,self.y0_tf)\n",
        "        self.u1_pred, self.v1_pred, _ , _ , _ , _ = self.net_uv(self.x1_tf,self.y1_tf)\n",
        "        self.f_u_pred, self.f_v_pred = self.net_f_uv(self.x_f_tf,self.y_f_tf)\n",
        "        \n",
        "        # Loss\n",
        "        self.loss = tf.reduce_mean(tf.square(self.u0_tf - self.u0_pred)) + \\\n",
        "                    tf.reduce_mean(tf.square(self.v0_tf - self.v0_pred)) + \\\n",
        "                    tf.reduce_mean(tf.square(self.u1_tf - self.u1_pred)) + \\\n",
        "                    tf.reduce_mean(tf.square(self.f_v_pred)) + \\\n",
        "                    tf.reduce_mean(tf.square(self.f_u_pred))\n",
        "        \n",
        "        # Optimizers\n",
        "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \n",
        "                                                                method = 'L-BFGS-B', \n",
        "                                                                options = {'maxiter': 50000,\n",
        "                                                                           'maxfun': 50000,\n",
        "                                                                           'maxcor': 50,\n",
        "                                                                           'maxls': 50,\n",
        "                                                                           'ftol' : 1.0* np.finfo(float).eps})\n",
        "    \n",
        "        self.optimizer_Adam = tf.train.AdamOptimizer()\n",
        "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)\n",
        "                \n",
        "\n",
        "        \n",
        "\n",
        "        # tf session\n",
        "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
        "                                                     log_device_placement=True))\n",
        "        \n",
        "        init = tf.global_variables_initializer()\n",
        "        self.sess.run(init)\n",
        "\n",
        "        \n",
        "              \n",
        "    def initialize_NN(self, layers):        \n",
        "        weights = []\n",
        "        biases = []\n",
        "        num_layers = len(layers) \n",
        "        for l in range(0,num_layers-1):\n",
        "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
        "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
        "            weights.append(W)\n",
        "            biases.append(b)        \n",
        "        return weights, biases\n",
        "        \n",
        "    def xavier_init(self, size):\n",
        "        in_dim = size[0]\n",
        "        out_dim = size[1]        \n",
        "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
        "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
        "    \n",
        "    def neural_net(self, X, weights, biases):\n",
        "        num_layers = len(weights) + 1\n",
        "        \n",
        "        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n",
        "        for l in range(0,num_layers-2):\n",
        "            W = weights[l]\n",
        "            b = biases[l]\n",
        "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
        "        W = weights[-1]\n",
        "        b = biases[-1]\n",
        "        Y = tf.add(tf.matmul(H, W), b)\n",
        "        return Y\n",
        "    \n",
        "    def net_uv(self, x, y):\n",
        "        X = tf.concat([x,y],1)\n",
        "        \n",
        "        uv = self.neural_net(X, self.weights, self.biases)\n",
        "        u = uv[:,0:1]\n",
        "        v = uv[:,1:2]\n",
        "          \n",
        "        u_x = tf.gradients(u, x)[0]\n",
        "        v_x = tf.gradients(v, x)[0]\n",
        "\n",
        "        u_y = tf.gradients(u, y)[0]\n",
        "        v_y = tf.gradients(v, y)[0]\n",
        "\n",
        "        return u, v, u_x, v_x, u_y, v_y\n",
        "\n",
        "    def net_f_uv(self, x):\n",
        "        u, v, u_x, v_x, u_y, v_y = self.net_uv(x)\n",
        "        \n",
        "        u_xx = tf.gradients(u_x, x)[0]\n",
        "        \n",
        "        v_xx = tf.gradients(v_x, x)[0]\n",
        "\n",
        "        u_yy = tf.gradients(u_y, y)[0]\n",
        "        \n",
        "        v_yy = tf.gradients(v_y, y)[0]\n",
        "        \n",
        "        \n",
        "        f_v = ( d1*u_xx + (-1)*r1*u + (1/k)*(nu*f1*u + nu*f2*v) ) + ( d1*u_yy + (-1)*r1*u + (1/k)*(nu*f1*u + nu*f2*v) )\n",
        "        f_u = ( d2*v_xx + (-1)*r2*v + s1*u ) + ( d2*v_yy + (-1)*r2*v + s1*u )   \n",
        "        \n",
        "        return f_u, f_v\n",
        "    \n",
        "    def callback(self, loss):\n",
        "        print('Loss:', loss)\n",
        "        \n",
        "    def train(self, nIter):\n",
        "        \n",
        "        tf_dict = {self.x0_tf: self.x0,\n",
        "                   self.x1_tf: self.x1,\n",
        "                   self.y0_tf: self.y0,\n",
        "                   self.y1_tf: self.y1,\n",
        "                   self.u0_tf: self.u0, self.v0_tf: self.v0,\n",
        "                   self.u1_tf: self.u1, self.v1_tf: self.v1,\n",
        "                   self.x_f_tf: self.x_f,\n",
        "                   self.y_f_tf: self.y_f}\n",
        "        \n",
        "        start_time = time.time()\n",
        "\n",
        "        restore_from_dir(self.sess, \"./ckpt1/\") \n",
        "\n",
        "        for it in range(nIter):\n",
        "            self.sess.run(self.train_op_Adam, tf_dict)\n",
        "            \n",
        "            # Print\n",
        "            if it % 10 == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                loss_value = self.sess.run(self.loss, tf_dict)\n",
        "                print('It: %d, Loss: %.3e, Time: %.2f' % \n",
        "                      (it, loss_value, elapsed))\n",
        "                start_time = time.time()\n",
        "            if it % 100 == 0:\n",
        "                self.saver.save(self.sess, './ckpt1/model',global_step=it,meta_graph_suffix='meta', write_meta_graph=True, write_state=True,\n",
        "                                strip_default_attrs=False, save_debug_info=False)\n",
        "\n",
        "        self.optimizer.minimize(self.sess, \n",
        "                                feed_dict = tf_dict,         \n",
        "                                fetches = [self.loss], \n",
        "                                loss_callback = self.callback)        \n",
        "                                    \n",
        "    \n",
        "    def predict(self, X_star):\n",
        "        \n",
        "        tf_dict = {self.x0_tf: X_star[:,0:1],self.y0_tf: Y_star[:,0:1]}\n",
        "        \n",
        "        u_star = self.sess.run(self.u0_pred, tf_dict)  \n",
        "        v_star = self.sess.run(self.v0_pred, tf_dict)  \n",
        "        \n",
        "        \n",
        "        tf_dict = {self.x_f_tf: X_star[:,0:1],self.y_f_tf: Y_star[:,0:1]}\n",
        "        \n",
        "        f_u_star = self.sess.run(self.f_u_pred, tf_dict)\n",
        "        f_v_star = self.sess.run(self.f_v_pred, tf_dict)\n",
        "               \n",
        "        return u_star, v_star, f_u_star, f_v_star\n",
        "    \n",
        "if __name__ == \"__main__\":        \n",
        "    \n",
        "    # Doman bounds\n",
        "    a = 2*np.pi #@param {}\n",
        "    lb = (-1)*a/2\n",
        "    ub = a/2\n",
        "\n",
        "    N0 = 2\n",
        "    N1 = 1\n",
        "    N_f = 40000\n",
        "    layers = [2, 100, 100, 100, 2]\n",
        "        \n",
        "    #CONSTANTS \n",
        "    d1 = 1 #@param {}\n",
        "    d2 = 0.8 #@param {}\n",
        "    r1 = 0.15 #@param {}\n",
        "    r2 = 0.3 #@param {}\n",
        "    s1 = 0.3 #@param {}\n",
        "    f1 = 0.55 #@param {}\n",
        "    f2 = 0.7 #@param {}\n",
        "    F = 2.5 #@param {}\n",
        "    nu = 1\n",
        "    k = ( (r2 + d2*((np.pi/a)**2)) * nu*f1 + s1*nu*f2) / ( (d1*((np.pi/a)**2) + r1) * (d2 * ((np.pi/a)**2) + r2))\n",
        "\n",
        "    x = np.linspace(lb,ub,2001)\n",
        "    x = np.reshape(x,(2001,1))\n",
        "\n",
        "    y = np.linspace(lb,ub,2001)\n",
        "    y = np.reshape(y,(2001,1))\n",
        "\n",
        "    Exact_u = F * np.cos((np.pi*x)/a) + F * np.cos((np.pi*y)/a)\n",
        "    Exact_v = (F * np.cos((np.pi*x)/a))*s1/(r2+d2*((np.pi/a)**2)) + (F * np.cos((np.pi*y)/a))*s1/(r2+d2*((np.pi/a)**2))\n",
        "\n",
        "    X, Y = np.meshgrid(x,y)\n",
        "    \n",
        "\n",
        "    X_star = x.flatten()[:,None]\n",
        "    Y_star = y.flatten()[:,None]\n",
        "    u_star = Exact_u.T.flatten()[:,None]\n",
        "    v_star = Exact_v.T.flatten()[:,None]\n",
        "    ###########################\n",
        "    \n",
        "    idx_x = np.array((0,2000))  # B.C. \n",
        "    x0 = x[idx_x,:]\n",
        "    u0x = Exact_u[idx_x,:]\n",
        "    v0x = Exact_v[idx_x,:]\n",
        "\n",
        "    idx_rand = np.random.choice(x.shape[0], N1, replace=False) # N1 random points (experimental data) \n",
        "    x1 = x[idx_rand,:]\n",
        "    u1x = Exact_u[idx_rand,:]\n",
        "    v1x = Exact_v[idx_rand,:]\n",
        "    \n",
        "    idx_y = np.array((0,2000))  # B.C. for Y\n",
        "    y0 = y[idx_y,:]\n",
        "    u0y = Exact_u[idx_y,:]\n",
        "    v0y = Exact_v[idx_y,:]\n",
        "\n",
        "    idy_rand = np.random.choice(x.shape[0], N1, replace=False) # N1 random points (experimental data) \n",
        "    y1 = y[idy_rand,:]\n",
        "    u1y = Exact_u[idy_rand,:]\n",
        "v1y = Exact_v[idy_rand,:]\n",
        "    \n",
        "    \n",
        "    X_f = lb + (ub-lb)*lhs(1, N_f)\n",
        "    Y_f = lb + (ub-lb)*lhs(1, N_f)\n",
        "\n",
        "    print(X_f.shape)        \n",
        "    model = PhysicsInformedNN(x0, u0x, v0x, x1, u1x, v1x, y0, u0y, v0y, y1, u1y, v1y, X_f, Y_f, layers, lb, ub)\n",
        "    \n",
        "    #@markdown Choose number of epoch\n",
        "    epoch = 1000 #@param {type:\"slider\", min:1000, max:10000, step:10}\n",
        "             \n",
        "    start_time = time.time()                \n",
        "    model.train(epoch)\n",
        "    elapsed = time.time() - start_time                \n",
        "    print('Training time: %.4f' % (elapsed))\n",
        "    \n",
        "        \n",
        "    u_pred, v_pred, f_u_pred, f_v_pred = model.predict(X_star)\n",
        "    h_pred = np.sqrt(u_pred**2 + v_pred**2)\n",
        "            \n",
        "    error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
        "    error_v = np.linalg.norm(v_star-v_pred,2)/np.linalg.norm(v_star,2)\n",
        "    print('Error u: %e' % (error_u))\n",
        "    print('Error v: %e' % (error_v))\n",
        "\n",
        "    \n",
        " \n",
        "    ######################################################################\n",
        "    ############################# Plotting ###############################\n",
        "    ######################################################################    \n",
        "    \n",
        "      \n",
        "\n",
        "    plt.plot(x,Exact_u[:], linewidth = 2,label = 'Exact')  \n",
        "    plt.scatter(x0,u0) \n",
        "    plt.scatter(x1,u1)     \n",
        "    plt.plot(x,u_pred[:], 'r', linewidth = 2, label = 'Prediction')\n",
        "    plt.xlabel('x')\n",
        "    plt.ylabel('phi1(t,x)')  \n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "    \n",
        "    plt.plot(x,Exact_v[:], linewidth = 2,label = 'Exact')       \n",
        "    plt.plot(x,v_pred[:], 'r', linewidth = 2, label = 'Prediction')\n",
        "    plt.scatter(x0,v0) \n",
        "    plt.xlabel('x')\n",
        "    plt.ylabel('phi2(t,x)')\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()    \n",
        "    \n",
        "   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyDOE\n",
            "  Downloading pyDOE-0.3.8.zip (22 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyDOE) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyDOE) (1.4.1)\n",
            "Building wheels for collected packages: pyDOE\n",
            "  Building wheel for pyDOE (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyDOE: filename=pyDOE-0.3.8-py3-none-any.whl size=18184 sha256=dabd284a2000e020a66542e5fd07f7ab9f446a7fb070af309bede9adb90f3a2a\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/ce/8a/87b25c685bfeca1872d13b8dc101e087a9c6e3fb5ebb47022a\n",
            "Successfully built pyDOE\n",
            "Installing collected packages: pyDOE\n",
            "Successfully installed pyDOE-0.3.8\n",
            "TensorFlow 1.x selected.\n",
            "[[1.46084058]] yo\n",
            "(40000, 1)\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\n",
            "\n",
            "No checkpoint to restore in ./ckpt1/\n",
            "It: 0, Loss: 3.255e+00, Time: 2.22\n",
            "It: 10, Loss: 2.151e+00, Time: 1.30\n",
            "It: 20, Loss: 1.640e+00, Time: 0.94\n",
            "It: 30, Loss: 1.658e+00, Time: 0.94\n",
            "It: 40, Loss: 1.609e+00, Time: 0.95\n",
            "It: 50, Loss: 1.603e+00, Time: 0.94\n",
            "It: 60, Loss: 1.578e+00, Time: 0.95\n",
            "It: 70, Loss: 1.520e+00, Time: 0.95\n",
            "It: 80, Loss: 1.350e+00, Time: 0.94\n",
            "It: 90, Loss: 1.032e+00, Time: 0.94\n",
            "It: 100, Loss: 7.382e-01, Time: 0.96\n",
            "It: 110, Loss: 6.044e-01, Time: 1.12\n",
            "It: 120, Loss: 4.643e-01, Time: 0.94\n",
            "It: 130, Loss: 3.785e-01, Time: 0.95\n",
            "It: 140, Loss: 3.110e-01, Time: 0.95\n",
            "It: 150, Loss: 2.521e-01, Time: 0.95\n",
            "It: 160, Loss: 1.950e-01, Time: 0.94\n",
            "It: 170, Loss: 1.369e-01, Time: 0.95\n",
            "It: 180, Loss: 8.389e-02, Time: 0.95\n",
            "It: 190, Loss: 4.677e-02, Time: 0.95\n",
            "It: 200, Loss: 3.008e-02, Time: 0.95\n",
            "It: 210, Loss: 1.906e-02, Time: 1.12\n",
            "It: 220, Loss: 1.285e-02, Time: 0.95\n",
            "It: 230, Loss: 9.055e-03, Time: 0.95\n",
            "It: 240, Loss: 6.132e-03, Time: 0.95\n",
            "It: 250, Loss: 4.504e-03, Time: 0.95\n",
            "It: 260, Loss: 3.364e-03, Time: 0.95\n",
            "It: 270, Loss: 2.586e-03, Time: 0.95\n",
            "It: 280, Loss: 2.051e-03, Time: 0.95\n",
            "It: 290, Loss: 1.671e-03, Time: 0.96\n",
            "It: 300, Loss: 1.391e-03, Time: 0.96\n",
            "It: 310, Loss: 1.179e-03, Time: 1.11\n",
            "It: 320, Loss: 1.015e-03, Time: 0.96\n",
            "It: 330, Loss: 8.836e-04, Time: 0.95\n",
            "It: 340, Loss: 7.766e-04, Time: 0.95\n",
            "It: 350, Loss: 6.874e-04, Time: 0.96\n",
            "It: 360, Loss: 6.149e-04, Time: 0.95\n",
            "It: 370, Loss: 3.278e-03, Time: 0.96\n",
            "It: 380, Loss: 2.821e-03, Time: 0.95\n",
            "It: 390, Loss: 2.424e-03, Time: 0.96\n",
            "It: 400, Loss: 4.258e-04, Time: 0.96\n",
            "It: 410, Loss: 6.745e-04, Time: 1.15\n",
            "It: 420, Loss: 3.687e-04, Time: 0.96\n",
            "It: 430, Loss: 3.691e-04, Time: 0.95\n",
            "It: 440, Loss: 3.069e-04, Time: 0.96\n",
            "It: 450, Loss: 2.749e-04, Time: 0.95\n",
            "It: 460, Loss: 2.518e-04, Time: 0.96\n",
            "It: 470, Loss: 2.314e-04, Time: 0.96\n",
            "It: 480, Loss: 2.123e-04, Time: 0.96\n",
            "It: 490, Loss: 1.951e-04, Time: 0.96\n",
            "It: 500, Loss: 1.796e-04, Time: 0.96\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "It: 510, Loss: 1.655e-04, Time: 1.16\n",
            "It: 520, Loss: 1.526e-04, Time: 0.96\n",
            "It: 530, Loss: 1.408e-04, Time: 0.96\n",
            "It: 540, Loss: 1.301e-04, Time: 0.96\n",
            "It: 550, Loss: 1.231e-04, Time: 0.96\n",
            "It: 560, Loss: 2.955e-03, Time: 0.96\n",
            "It: 570, Loss: 8.104e-03, Time: 0.96\n",
            "It: 580, Loss: 1.922e-03, Time: 0.96\n",
            "It: 590, Loss: 1.094e-04, Time: 0.96\n",
            "It: 600, Loss: 3.872e-04, Time: 0.96\n",
            "It: 610, Loss: 2.300e-04, Time: 1.14\n",
            "It: 620, Loss: 8.521e-05, Time: 0.96\n",
            "It: 630, Loss: 1.007e-04, Time: 0.96\n",
            "It: 640, Loss: 7.481e-05, Time: 0.98\n",
            "It: 650, Loss: 7.142e-05, Time: 0.97\n",
            "It: 660, Loss: 6.650e-05, Time: 0.97\n",
            "It: 670, Loss: 6.177e-05, Time: 0.97\n",
            "It: 680, Loss: 5.788e-05, Time: 0.97\n",
            "It: 690, Loss: 5.441e-05, Time: 0.97\n",
            "It: 700, Loss: 5.123e-05, Time: 0.98\n",
            "It: 710, Loss: 4.827e-05, Time: 1.18\n",
            "It: 720, Loss: 4.555e-05, Time: 0.97\n",
            "It: 730, Loss: 4.302e-05, Time: 0.97\n",
            "It: 740, Loss: 4.068e-05, Time: 0.97\n",
            "It: 750, Loss: 3.850e-05, Time: 0.97\n",
            "It: 760, Loss: 3.647e-05, Time: 0.96\n",
            "It: 770, Loss: 3.459e-05, Time: 0.96\n",
            "It: 780, Loss: 3.284e-05, Time: 0.96\n",
            "It: 790, Loss: 3.120e-05, Time: 0.97\n",
            "It: 800, Loss: 2.984e-05, Time: 0.97\n",
            "It: 810, Loss: 5.954e-05, Time: 1.15\n",
            "It: 820, Loss: 1.299e-02, Time: 0.97\n",
            "It: 830, Loss: 3.024e-05, Time: 0.96\n",
            "It: 840, Loss: 2.012e-03, Time: 0.97\n",
            "It: 850, Loss: 4.307e-04, Time: 0.96\n",
            "It: 860, Loss: 1.410e-04, Time: 0.97\n",
            "It: 870, Loss: 1.367e-04, Time: 0.97\n",
            "It: 880, Loss: 2.958e-05, Time: 0.96\n",
            "It: 890, Loss: 2.730e-05, Time: 0.97\n",
            "It: 900, Loss: 2.708e-05, Time: 0.97\n",
            "It: 910, Loss: 2.406e-05, Time: 1.15\n",
            "It: 920, Loss: 2.198e-05, Time: 0.98\n",
            "It: 930, Loss: 2.063e-05, Time: 0.97\n",
            "It: 940, Loss: 1.964e-05, Time: 0.96\n",
            "It: 950, Loss: 1.885e-05, Time: 0.96\n",
            "It: 960, Loss: 1.813e-05, Time: 0.96\n",
            "It: 970, Loss: 1.743e-05, Time: 0.97\n",
            "It: 980, Loss: 1.679e-05, Time: 0.97\n",
            "It: 990, Loss: 1.617e-05, Time: 0.97\n",
            "Loss: 1.5648175e-05\n",
            "Loss: 37.042168\n",
            "Loss: 1.5646008e-05\n",
            "Loss: 1.5642407e-05\n",
            "Loss: 1.5628291e-05\n",
            "Loss: 1.5575926e-05\n",
            "Loss: 1.5024268e-05\n",
            "Loss: 1.4429916e-05\n",
            "Loss: 1.3874784e-05\n",
            "Loss: 1.3755005e-05\n",
            "Loss: 1.3558918e-05\n",
            "Loss: 1.3510837e-05\n",
            "Loss: 1.3361563e-05\n",
            "Loss: 1.2990689e-05\n",
            "Loss: 1.2196166e-05\n",
            "Loss: 1.1668967e-05\n",
            "Loss: 1.1279442e-05\n",
            "Loss: 1.1198572e-05\n",
            "Loss: 1.1164348e-05\n",
            "Loss: 1.1046624e-05\n",
            "Loss: 1.0745873e-05\n",
            "Loss: 1.0112493e-05\n",
            "Loss: 9.201402e-06\n",
            "Loss: 9.74377e-06\n",
            "Loss: 8.851589e-06\n",
            "Loss: 8.348653e-06\n",
            "Loss: 8.214707e-06\n",
            "Loss: 8.193578e-06\n",
            "Loss: 8.160743e-06\n",
            "Loss: 8.065314e-06\n",
            "Loss: 7.90466e-06\n",
            "Loss: 7.670384e-06\n",
            "Loss: 7.431099e-06\n",
            "Loss: 7.2522894e-06\n",
            "Loss: 7.1525656e-06\n",
            "Loss: 6.900626e-06\n",
            "Loss: 6.5783315e-06\n",
            "Loss: 6.2211575e-06\n",
            "Loss: 6.0498023e-06\n",
            "Loss: 5.961271e-06\n",
            "Loss: 5.8968426e-06\n",
            "Loss: 5.7219686e-06\n",
            "Loss: 5.4407164e-06\n",
            "Loss: 5.0967265e-06\n",
            "Loss: 4.8916354e-06\n",
            "Loss: 4.8441243e-06\n",
            "Loss: 4.8361817e-06\n",
            "Loss: 4.825815e-06\n",
            "Loss: 4.809515e-06\n",
            "Loss: 4.793179e-06\n",
            "Loss: 4.7880308e-06\n",
            "Loss: 4.7860112e-06\n",
            "Loss: 4.7843528e-06\n",
            "Loss: 4.7819854e-06\n",
            "Loss: 4.772889e-06\n",
            "Loss: 4.7545595e-06\n",
            "Loss: 4.7127637e-06\n",
            "Loss: 8.762396e-06\n",
            "Loss: 4.708586e-06\n",
            "Loss: 4.646422e-06\n",
            "Loss: 4.5863762e-06\n",
            "Loss: 4.5684797e-06\n",
            "Loss: 4.5661786e-06\n",
            "Loss: 4.5657785e-06\n",
            "Loss: 4.613727e-06\n",
            "Loss: 4.5656047e-06\n",
            "Loss: 4.564348e-06\n",
            "Loss: 4.5569877e-06\n",
            "Loss: 4.4955723e-06\n",
            "Loss: 4.3885375e-06\n",
            "Loss: 4.1852095e-06\n",
            "Loss: 3.8055318e-06\n",
            "Loss: 3.3428305e-06\n",
            "Loss: 2.9451496e-06\n",
            "Loss: 2.9050861e-06\n",
            "Loss: 2.8992279e-06\n",
            "Loss: 2.895967e-06\n",
            "Loss: 2.894928e-06\n",
            "Loss: 2.894143e-06\n",
            "Loss: 2.8932218e-06\n",
            "Loss: 2.8923896e-06\n",
            "Loss: 2.891094e-06\n",
            "Loss: 2.888621e-06\n",
            "Loss: 2.8832883e-06\n",
            "Loss: 2.869772e-06\n",
            "Loss: 2.837647e-06\n",
            "Loss: 2.7905173e-06\n",
            "Loss: 2.729272e-06\n",
            "Loss: 2.6454213e-06\n",
            "Loss: 2.6291386e-06\n",
            "Loss: 2.6101388e-06\n",
            "Loss: 2.6017683e-06\n",
            "Loss: 2.5985787e-06\n",
            "Loss: 2.5971428e-06\n",
            "Loss: 2.59548e-06\n",
            "Loss: 2.5933778e-06\n",
            "Loss: 2.58666e-06\n",
            "Loss: 2.571343e-06\n",
            "Loss: 2.531766e-06\n",
            "Loss: 2.4318908e-06\n",
            "Loss: 2.1901203e-06\n",
            "Loss: 1.9838792e-06\n",
            "Loss: 1.5748753e-06\n",
            "Loss: 1.1819399e-06\n",
            "Loss: 1.1057625e-06\n",
            "Loss: 1.069441e-06\n",
            "Loss: 1.0238068e-06\n",
            "Loss: 9.764617e-07\n",
            "Loss: 9.4746025e-07\n",
            "Loss: 9.0107153e-07\n",
            "Loss: 8.510072e-07\n",
            "Loss: 8.2644954e-07\n",
            "Loss: 8.0163676e-07\n",
            "Loss: 8.376834e-07\n",
            "Loss: 7.9332926e-07\n",
            "Loss: 7.858898e-07\n",
            "Loss: 7.808647e-07\n",
            "Loss: 7.7848256e-07\n",
            "Loss: 7.781555e-07\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
            "  Objective function value: 0.000001\n",
            "  Number of iterations: 111\n",
            "  Number of functions evaluations: 119\n",
            "Training time: 116.7556\n",
            "Error u: 5.132797e-05\n",
            "Error v: 6.454101e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHmVQ_wxlMAx"
      },
      "source": [
        "plt.plot(x,Exact_u[:], linewidth = 2,label = 'Exact')  \n",
        "plt.scatter(x0,u0) \n",
        "plt.scatter(x1,u1)     \n",
        "plt.plot(x,u_pred[:], 'r', linewidth = 2, label = 'Prediction')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('phi1(t,x)')  \n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(x,Exact_v[:], linewidth = 2,label = 'Exact')       \n",
        "plt.plot(x,v_pred[:], 'r', linewidth = 2, label = 'Prediction')\n",
        "plt.scatter(x0,v0) \n",
        "plt.xlabel('x')\n",
        "plt.ylabel('phi2(t,x)')\n",
        "plt.legend(loc='best')\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}